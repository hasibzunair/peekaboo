<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Peekaboo for Unsupervised Object Localization</title>
	<meta property="og:image" content="./resources/model.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="(WEBPAGE UNDER DEVELOPMENT!) PEEKABOO: Hiding Parts of an Image for Unsupervised Object Localization" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">(WEBPAGE UNDER DEVELOPMENT!) PEEKABOO: Hiding Parts of an Image for Unsupervised Object Localization</span>
		<table align=center width=600px>
			<table align=center width=450px> <!--Adjust for spacing between author names-->
				<tr>
					<!--Add author names here.-->
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="http://hasibzunair.github.io/">Hasib Zunair</a><sup>1</sup></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://users.encs.concordia.ca/~hamza/">A. Ben Hamza</a><sup>1</sup></span>
						</center>
					</td>
					<!--
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://en.wikipedia.org/wiki/James_J._Gibson">Second Author</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://en.wikipedia.org/wiki/James_J._Gibson">Third Author</a></span>
						</center>
					</td>
					-->
				</tr>
			</table>

			<!--Add affiliations here.-->
			<table align="center" width="700px">
				<tbody>
					<tr>
						<td align="center" width="200px">
							<center>
								<span style="font-size:24px"><sup>1</sup>Concordia University, Montreal, QC, Canada.</span>
							</center>
						</td>
						<!--
						<td align="center" width="200px">
							<center>
							<span style="font-size:20px"><sup>2</sup>University X</span>
							</center>
						</td>
						-->
			 		</tr>
				</tbody>
			</table>

			<!--Add publication details here.-->
			<table align="center" width="750px">
				<tbody>
					<tr>
						<td align="center" width="100px">
							<center>
								<span style="font-size:25px; color: crimson;">IEEE/CVF Winter Conference on Applications of Computer Vision WACV 2024</span>
							</center>
							<!--
							<center>
								<span style="font-size:20px">Digital Geometric Modelling</span>
							</center>
							-->
						</td>
					</tr>
				</tbody>
			</table>

			<!--Add supplementary links here.-->
			<table align=center width=500px>
				<tr>
					
					<td align=center width=80px>
						<center>
							<span style="font-size:24px"><a href='https://huggingface.co/spaces/hasibzunair/msl-recognition-demo'>[Demo]</a></span><br>
						</center>
					</td>
					
					<td align=center width=80px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/hasibzunair/msl-recognition'>[GitHub]</a></span><br>
						</center>
					</td>
					
					<td align=center width=80px>
						<center>
							<span style="font-size:24px"><a href='https://openaccess.thecvf.com/content/WACV2024/html/Zunair_Learning_To_Recognize_Occluded_and_Small_Objects_With_Partial_Inputs_WACV_2024_paper.html'>[Paper]</a></span>
						</center>
					</td>


					<td align=center width=80px>
						<center>
							<span style="font-size:24px"><a href='https://youtu.be/koxIipyvmZk?si=AQI_LmsivzZCulDm'>[Video]</a></span>
						</center>
					</td>


					<td align=center width=80px>
						<center>
							<span style="font-size:24px"><a href='poster.pdf'>[Poster]</a></span>
						</center>
					</td>
					
					<!--  
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href=''>[Talk]</a></span><br>
						</center>
					</td>
					
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href=''>[Slides]</a></span><br>
						</center>
					</td>
					
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href=''>[Poster]</a></span><br>
						</center>
					</td>
					-->
				</tr>
			</table>
		</table>
	</center>

	<br>
	
	<center> 
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<!--Add intro image here.-->
						<img class="round" style="width:850px" src="./resources/compare_predictions.png"/>
						
					</center>
				</td>
			</tr>

			<tr>
				<td width="600px">
					<center>
						<span style="font-size:16px"><i><strong>Visual comparison of MSL (Ours) and CSRA on VOC2007 and MS-COCO datasets</strong>. First two rows show samples from 
							VOC2007 where MSL can better recognize small objects and the second row shows cases of heavy occlusions. The last two rows 
							shows samples from MS-COCO. For both datasets, MSL is effective at recognizing <strong>small</strong> and <strong>occluded</strong> 
							objects compared to the baseline.</i>
						</span>
					</center>
				</td>
			</tr>
		</table>
	</center>

	<br>
	<hr>
		<div class="disclaimerbox">
		  	<!-- <center><h2>How to interpret the results</h2></center> -->

		 	<span style="color:#646464">
			  	
				<center><span style="font-size:28px"><b>How to interpret the results</b></span></center>
			
				<br>
		  
				<i> 
					Aloha! While computer vision algorithms work well on some images, they often fail in others largely due to 
					small size of objects and occlusions. Even though this is not a solved problem, quite far from it, 
					we believe our work is a significant step forward in solving 
					the recognition of small and occluded objects. There has been some concurrent work on this subject as well. 
					Specifically, see <a href="https://arxiv.org/abs/2007.01755">MCAR</a>.
				</i>

				<br><br>

				<i> 
					Our appraoch aims to explicitly focus on context from neighbouring regions around objects. Further, 
					this also enables to learn a distribution of association across classes. Ideally to handle situations in-the-wild where 
					only part of some object class is visible, but where us humans might readily use context to infer the classes presence.
				</i>

				<br><br>

				<i>
					We also explored this technique in our previous 
					work <a href="https://arxiv.org/abs/2210.00923"><strong>Masked Supervised Learning for Semantic Segmentation</strong></a> (BMVC 2022, Oral)
					where we find that MSL trained 
					models are significantly compute efficient, better segments ambiguous and small regions, and is shape aware as it enables to quite well 
					segment heavily masked regions.
				</i>

				<br><br>

				<i>Do enjoy our results, and definitely <a href="https://huggingface.co/spaces/hasibzunair/msl-recognition-demo">try the model</a> yourself</i>!
	  		</span>
	  	</div>

	<br>
	<hr>

	<table align=center width=900px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Recognizing multiple objects in an image is challenging due to occlusions, and becomes even more 
				so when the objects are small. While promising, existing multi-label image recognition models do not 
				explicitly learn context-based representations, and hence 
				<FONT COLOR="#ff0000">struggle to correctly recognize small and occluded objects</FONT>. Intuitively, recognizing occluded 
				objects requires knowledge of partial input, and hence context. Motivated by this intuition, we 
				propose <strong>Masked Supervised Learning (MSL)</strong>, a single-stage, model-agnostic 
				learning paradigm for multi-label image recognition. The key idea is to learn context-based representations 
				using a masked branch and to model label co-occurrence using label consistency. 
				Experimental results demonstrate the <FONT COLOR="#46C646">simplicity, applicability and 
				more importantly the competitive performance</FONT> of MSL against previous state-of-the-art methods 
				on standard multi-label image recognition benchmarks. In addition, we show that MSL is robust to random 
				masking and demonstrate its effectiveness in recognizing non-masked objects.
			</td>
		</tr>
	</table>
	
	<br>
	<hr>

	<!--Add YouTube talk here.-->
	<!--
	<center><h1>Talk</h1></center>
	<p align="center">
		<iframe width="660" height="395" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
	</p>

	<table align=center width=800px>
		<br>
		<tr>
			<center>
				<span style="font-size:28px"><a href=''>[Slides]</a>
				</span>
			</center>
		</tr>
	</table>
	<br>
	<hr>
	-->

	<!--Add demo code here with architecture.-->
	<center><h1>Our Method</h1></center>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:850px" src="./resources/figure.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<br>
	<hr>

	<table align=center width=500px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">Hasib Zunair and A. Ben Hamza<br>
				<b>Learning to Recognize Occluded and Small Objects with Partial Inputs.</b><br>
				In WACV, 2024.<br>
				<!--Add arXiv link-->
				(hosted on <a href="https://arxiv.org/abs/2310.18517">ArXiv</a>)<br>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<!--Add Bibtex-->
	<!--
	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>
	-->

	<br>
	<hr>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					<center>This website template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a>, code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.</center>
				</left>
			</td>
		</tr>
	</table>
<br>

</body>
</html>